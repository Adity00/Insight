<div align="center">

# ğŸ” InsightX

### Conversational AI Analytics for UPI Payment Data

[![Python](https://img.shields.io/badge/Python-3.11%20%7C%203.12-blue?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Next.js](https://img.shields.io/badge/Next.js-16.1-000000?logo=nextdotjs&logoColor=white)](https://nextjs.org)
[![DuckDB](https://img.shields.io/badge/DuckDB-0.10.3-FFC107)](https://duckdb.org)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-412991?logo=openai&logoColor=white)](https://openai.com)

**Ask any business question about 250,000 UPI transactions in plain English.**
**Get a statistically enriched, data-backed answer in seconds.**

_IIT Bombay Techfest 2025-26 â€” InsightX: Leadership Analytics Challenge_

---

[Setup Guide](SETUP.md) Â· [API Docs](http://localhost:8000/docs) Â· [Architecture](#architecture)

</div>

---

## The Problem

A payments company has 250,000 UPI transactions. The CEO asks:
_"Which merchant categories show the highest failure rates during peak hours?"_

The data analyst is in a meeting. The CEO can't write SQL. The insight never reaches the decision-maker.

This is not a tooling problem. This is a **translation problem** â€” between human intent and database computation. InsightX solves it.

---

## What InsightX Does

InsightX is a conversational analytics engine. You ask questions in plain English. It returns statistically enriched, business-ready answers â€” with charts, benchmarks, z-scores, and actionable recommendations.

```
You  â†’ "Which state has the highest fraud flag rate?"

InsightX â†’ Karnataka leads at 0.23% (z-score: 1.53), significantly above
           the national average of 0.19%. Rajasthan follows at 0.23%.
           Neither state exceeds z=2.0, indicating variation is within
           normal range â€” no confirmed anomaly requiring immediate action.

           [Bar chart, ranked by fraud rate across all 10 states]
           [Actionable Recommendation: Monitor Karnataka and Rajasthan
           transactions during off-peak hours when manual review capacity
           is higher.]
```

It also remembers context across turns:

```
You       â†’ "Which bank has the most failed transactions?"
InsightX  â†’ "SBI leads with 3,095 failed transactions..."

You       â†’ "What percentage of their transactions is that?"
InsightX  â†’ "SBI's failure rate is 4.94% of their 62,693 total..."

You       â†’ "Compare with HDFC"
InsightX  â†’ "HDFC has a 4.82% failure rate. Both are within normal range."
```

No repeated context. No rephrasing. Natural conversation.

---

## Why Not The Obvious Approaches

Before explaining what we built, here is what we deliberately chose NOT to build â€” and why.

### âŒ Direct LLM (Send question to GPT-4, display response)

GPT-4 doesn't have your data. It will confidently fabricate numbers.
_"Food has a 12% failure rate"_ when the actual answer is 4.3%.
For business decisions, invented numbers are worse than no numbers.
**This approach fails the 30% accuracy criterion immediately.**

### âŒ RAG (Retrieval Augmented Generation)

RAG is the right tool for document search â€” _"What does our refund policy say?"_
It is fundamentally wrong for analytics.

RAG finds "similar" chunks. Analytics requires computation.
You cannot GROUP BY with cosine similarity.
You cannot compute an average by finding the most "relevant" rows.

_RAG says:_ "Here are some transactions that might be relevant."
_SQL says:_ "The average is exactly â‚¹1,311.76 computed across all 250,000 rows."

**For structured numerical data, retrieval cannot replace computation.**

### âŒ Fine-Tuning

Training GPT on your specific dataset so it "knows" the numbers.
Problems: costs thousands of dollars, doesn't update dynamically,
still hallucinates, requires ML infrastructure, takes weeks.
**Not viable for a deadline-driven project.**

### âŒ Rule-Based NLP

Parsing questions with hand-written rules:
_"if question contains 'average' and 'amount', compute mean"_

Breaks immediately on any question you didn't anticipate.
_"What's the typical spend?"_ â€” your rule doesn't know "typical" means average.
_"Which hour sees peak activity?"_ â€” "peak" isn't in your rules.

**Natural language has infinite variation. Rules don't scale.**

### âœ… What We Built: Controlled Text-to-SQL

Text-to-SQL is the industry-standard approach used by Tableau AI,
Microsoft Copilot for Power BI, ThoughtSpot, and Amazon QuickSight Q.

The principle: **AI understands language. Databases compute numbers. Keep them separate.**

GPT-4's job is never to know the data. Its job is to write SQL.
DuckDB's job is to compute. DuckDB is always right.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query (Natural Language)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FastAPI Backend                       â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Intent          â”‚    â”‚ Session Manager              â”‚  â”‚
â”‚   â”‚ Classifier      â”‚    â”‚ Entity Tracker               â”‚  â”‚
â”‚   â”‚                 â”‚    â”‚ Pronoun Resolution           â”‚  â”‚
â”‚   â”‚ GREETING â”€â”€â”€â”€â”€â”€â–ºâ”‚    â”‚ 8-Turn Memory Window         â”‚  â”‚
â”‚   â”‚ KNOWLEDGE â”€â”€â”€â”€â”€â–ºâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”‚ DATA_QUERY â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚                  â”‚
â”‚                                         â–¼                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚   GPT-4 Pass 1   â”‚          â”‚
â”‚                              â”‚  SQL Generation  â”‚          â”‚
â”‚                              â”‚  temperature=0   â”‚          â”‚
â”‚                              â”‚  10 few-shot ex. â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                       â”‚                    â”‚
â”‚                                       â–¼                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚  SQL Validator   â”‚          â”‚
â”‚                              â”‚  Security layer  â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                       â”‚                    â”‚
â”‚                                       â–¼                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚  DuckDB Engine   â”‚          â”‚
â”‚                              â”‚  250k rows       â”‚          â”‚
â”‚                              â”‚  <100ms queries  â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                       â”‚                    â”‚
â”‚                                       â–¼                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚  Stats Engine    â”‚          â”‚
â”‚                              â”‚  Z-scores        â”‚          â”‚
â”‚                              â”‚  Benchmarks      â”‚          â”‚
â”‚                              â”‚  Deviation       â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                       â”‚                    â”‚
â”‚                                       â–¼                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚   GPT-4 Pass 2   â”‚          â”‚
â”‚                              â”‚    Narration     â”‚          â”‚
â”‚                              â”‚  temperature=0.3 â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Next.js Frontend                        â”‚
â”‚         Chat Interface Â· Charts Â· KPI Dashboard             â”‚
â”‚              SQL Viewer Â· Proactive Insights                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Two-Pass GPT-4 Design

Most systems use one GPT-4 call. We use two deliberately:

**Pass 1 â€” SQL Generation** runs at `temperature=0` (fully deterministic).
SQL must be exact. A temperature above 0 introduces randomness into column names and filters â€” unacceptable for accuracy.

**Pass 2 â€” Narration** runs at `temperature=0.3` (slight creativity).
Business language benefits from natural variation. You don't want
every answer starting with the same phrase.

Splitting these concerns into two calls with different temperatures
is the key architectural decision that makes both accuracy and
answer quality achievable simultaneously.

---

## Tech Stack â€” Every Decision Justified

| Component    | Choice          | Why This, Not Alternatives                                                                                                                                                                                                                                    |
| ------------ | --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Backend**  | FastAPI         | Async by default â€” handles concurrent requests while GPT-4 is processing. Auto-generates Swagger docs. Pydantic validation catches malformed requests before they reach the pipeline. Flask is sync. Django is overkill.                                      |
| **Database** | DuckDB          | Built specifically for analytical queries. Runs in-memory â€” no server, no config. Speaks standard SQL (GPT-4 target). 50-100x faster than Pandas on GROUP BY across 250k rows. PostgreSQL requires a running server. SQLite is transactional, not analytical. |
| **AI**       | GPT-4           | Writes accurate SQL on complex schemas. Handles NULL values, multi-table joins, proper GROUP BY. GPT-3.5 makes SQL mistakes that break results. For a system where accuracy is 30% of judging, model quality directly affects score.                          |
| **Frontend** | Next.js 16      | App Router with server-side rendering. The team's strongest framework.                                                                                                                                                                                        |
| **Charts**   | Recharts        | Native React components. Matches our API response shape exactly. Responsive containers built in.                                                                                                                                                              |
| **Styling**  | Tailwind CSS v4 | No class naming decisions. Consistent design system. Fast to build with utility classes.                                                                                                                                                                      |
| **State**    | Zustand         | Minimal boilerplate for session and message state. Redux is overkill for this scope.                                                                                                                                                                          |

---

## Key Technical Innovations

### 1. Pronoun-Aware Context Injection

The hardest problem in multi-turn analytics is context bleed â€”
where filters from a previous question contaminate a new unrelated question.

Standard approach: inject all prior context into every request.
Problem: _"Which bank has the highest failure rate?"_ after discussing Maharashtra
would incorrectly filter to Maharashtra transactions only.

Our approach: detect reference pronouns (`those`, `them`, `that`, `same`, `their`)
using word boundary regex. Context is injected ONLY if the new question
contains reference words OR explicitly re-mentions a prior entity.
General questions get zero prior context â€” they always query the full dataset.

### 2. Statistical Enrichment Layer

Raw numbers without context mislead. _"Karnataka has a 0.23% fraud rate"_ means
nothing without knowing the national average is 0.19%.

The stats engine computes z-scores, mean deviation, and percentile rank
for every numerical result before narration. GPT-4 receives
pre-computed context: _"Karnataka is 1.53 standard deviations above mean"._

This prevents the most common LLM failure mode: misinterpreting magnitude.

### 3. SQL Security Validation

Every GPT-4 generated SQL passes through `sql_validator.py` before execution:

- Non-SELECT statements â†’ rejected
- `DROP`, `DELETE`, `INSERT`, `UPDATE` â†’ rejected
- `--` (SQL comment injection) â†’ rejected
- Semicolons â†’ stripped
- Queries exceeding 2000 characters â†’ rejected

The validator runs before every database call. No exceptions.

### 4. Compound Question Decomposition

_"Compare fraud rates by state for P2P transactions on weekends vs weekdays"_
is actually three questions: filter P2P, group by state, split by weekend flag.

The system detects compound questions, decomposes them into sub-questions,
runs each in an isolated temporary session (preventing cross-contamination),
then synthesizes a unified business answer.

---

## Evaluation Criteria Alignment

The system architecture was designed around the judging rubric â€” not the other way around:

| Criterion              | Weight | How InsightX Addresses It                                                                                  |
| ---------------------- | ------ | ---------------------------------------------------------------------------------------------------------- |
| Insight Accuracy       | 30%    | Real SQL on real data. DuckDB computes exact numbers. Zero hallucination. 9.5/10 verified on ground truth. |
| Query Understanding    | 25%    | 6 query categories, compound decomposition, ambiguity detection, graceful error handling.                  |
| Explainability         | 20%    | Z-scores, benchmarks, business implications, transparent SQL viewer on every response.                     |
| Conversational Quality | 15%    | 8-turn memory, entity tracking, pronoun resolution, natural follow-up handling.                            |
| Innovation & Tech      | 10%    | Two-pass GPT-4, statistical enrichment layer, pronoun-aware context injection.                             |

---

## Dataset

250,000 synthetic UPI transactions across 17 columns provided by IIT Bombay Techfest organizers. Includes transaction type, amount, sender/receiver demographics, bank, device, network type, and fraud flag.

> âš ï¸ `fraud_flag = 1` indicates a transaction flagged for automated review â€” NOT confirmed fraud. InsightX always surfaces this distinction in its answers.

---

## Setup

â†’ **[See SETUP.md for full installation guide](SETUP.md)**

---

## Project Structure

```
insightx/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ query_pipeline.py    # Main orchestrator: intent â†’ SQL â†’ DB â†’ stats â†’ narration
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py    # GPT-4 prompt construction, few-shot examples, ambiguity detection
â”‚   â”‚   â”œâ”€â”€ database.py          # DuckDB CSV loader, query executor, data profile cache
â”‚   â”‚   â”œâ”€â”€ session_manager.py   # In-memory session store, entity tracker, 8-turn context window
â”‚   â”‚   â”œâ”€â”€ persistence.py       # SQLite-backed session/turn storage for cross-restart history
â”‚   â”‚   â”œâ”€â”€ sql_validator.py     # Read-only SQL enforcer â€” blocks DROP/DELETE/injection
â”‚   â”‚   â””â”€â”€ stats_engine.py      # Z-scores, trend detection, anomaly verdict generation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic request/response models for all API endpoints
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat.py              # POST /api/chat â€” validates session, runs pipeline, persists turn
â”‚   â”‚   â”œâ”€â”€ dashboard.py         # GET /api/dashboard â€” returns KPI metrics from data profile
â”‚   â”‚   â””â”€â”€ sessions.py          # CRUD /api/sessions â€” create, list, delete, rename, restore
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ upi_transactions_2024.csv   # Official Techfest dataset (250,000 rows, 17 columns)
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point, CORS config, router registration
â”‚   â”œâ”€â”€ test_api.py              # Integration tests for chat and session endpoints
â”‚   â”œâ”€â”€ test_context_fix.py      # Tests for pronoun resolution and context injection logic
â”‚   â”œâ”€â”€ test_db.py               # DuckDB initialization and query execution tests
â”‚   â”œâ”€â”€ test_pipeline.py         # End-to-end pipeline smoke tests
â”‚   â”œâ”€â”€ test_prompt_builder.py   # Unit tests for SQL and narration prompt construction
â”‚   â””â”€â”€ test_refinements.py      # Regression tests for edge cases and answer quality
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ layout.tsx       # Root layout, Geist font setup, HTML metadata
â”‚       â”‚   â”œâ”€â”€ page.tsx         # Main app shell: sidebar, session management, KPI + chat layout
â”‚       â”‚   â””â”€â”€ globals.css      # CSS custom properties, design tokens, global styles
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatWindow.tsx   # Chat UI, message rendering, PDF export, pin/save actions
â”‚       â”‚   â”œâ”€â”€ KPICards.tsx     # Dashboard metric cards with INR formatting and pulse indicators
â”‚       â”‚   â””â”€â”€ Visualizations.tsx  # Recharts bar, line, pie, area chart renderer
â”‚       â””â”€â”€ lib/
â”‚           â””â”€â”€ api.ts           # Typed fetch wrappers for all backend REST endpoints
â”œâ”€â”€ .env.example                 # Template â€” copy to .env and add API key from team
â”œâ”€â”€ requirements.txt             # Python dependencies with pinned versions
â”œâ”€â”€ SETUP.md                     # Step-by-step installation and troubleshooting guide
â””â”€â”€ README.md                    # This file
```

---

## Known Limitations

| Limitation                 | Context                                                                                           |
| -------------------------- | ------------------------------------------------------------------------------------------------- |
| Response time 3-8 seconds  | Two sequential GPT-4 API calls. Acceptable for a demo. Production fix: streaming + query caching. |
| Sessions lost on restart   | Sessions are in-memory. Production fix: Redis persistence.                                        |
| GPT-4 SQL accuracy ~92-95% | One automatic retry handles most failures. Rare complex queries may produce unexpected results.   |

---

<div align="center">

Built for **IIT Bombay Techfest 2025-26**
InsightX: Leadership Analytics Challenge

</div>
